{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1iFragKBkCsPLUUEJdXfCYMeGAV2zVEDx","authorship_tag":"ABX9TyP27SOQZfGu1fUBv4hVVIzg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"3e4802adb6714afaa1e016970c9d793b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_146eb1a2a5eb42bd9d6945d890c36187","IPY_MODEL_2f1b3208c50e46cd9b4944a76283926a","IPY_MODEL_427efcd50fcb4c3ab175849c44e586aa"],"layout":"IPY_MODEL_9c82c611810d4debbf4f5c7da5eb6190"}},"146eb1a2a5eb42bd9d6945d890c36187":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_81c0fc7cabc14d74b1ae3170eb5fcf94","placeholder":"​","style":"IPY_MODEL_e35fc0d848a04f5aa351c1ac0fb4af88","value":"tokenizer_config.json: 100%"}},"2f1b3208c50e46cd9b4944a76283926a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_92832dff7945480091f8ac7c8cf5f616","max":29,"min":0,"orientation":"horizontal","style":"IPY_MODEL_20c19b37eed74650ae6c7078bc64bf7a","value":29}},"427efcd50fcb4c3ab175849c44e586aa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_04d62922c977427d8fcd28453c5b6eef","placeholder":"​","style":"IPY_MODEL_60d67f9fa9d7438bb899576d84c575ca","value":" 29.0/29.0 [00:00&lt;00:00, 1.72kB/s]"}},"9c82c611810d4debbf4f5c7da5eb6190":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81c0fc7cabc14d74b1ae3170eb5fcf94":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e35fc0d848a04f5aa351c1ac0fb4af88":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"92832dff7945480091f8ac7c8cf5f616":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"20c19b37eed74650ae6c7078bc64bf7a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"04d62922c977427d8fcd28453c5b6eef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60d67f9fa9d7438bb899576d84c575ca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8da36af329a4445b9386a21e3fd0ae3f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a7b7002986be465a80f5a19be3604f45","IPY_MODEL_46148d16b93d4108830d6378be2c53c5","IPY_MODEL_b0baa8fb4b4c4ff2b8356adaf11171a7"],"layout":"IPY_MODEL_baf8ae025ecc4a3eb68cd609858d20d0"}},"a7b7002986be465a80f5a19be3604f45":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_13bfcdbd67d04d5a86c89a61039aec5d","placeholder":"​","style":"IPY_MODEL_0aa9b67b9072433ba1007b392d85a2ab","value":"vocab.txt: 100%"}},"46148d16b93d4108830d6378be2c53c5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5793cb1191ad4082bf320e083ec9034a","max":995526,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7946a83fa6eb45e48e6811301dee9564","value":995526}},"b0baa8fb4b4c4ff2b8356adaf11171a7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f592a10f67b4b14a97bccc9c70e8b0e","placeholder":"​","style":"IPY_MODEL_fd3e760ee20a45c89b04fbd0808a9908","value":" 996k/996k [00:00&lt;00:00, 7.99MB/s]"}},"baf8ae025ecc4a3eb68cd609858d20d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13bfcdbd67d04d5a86c89a61039aec5d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0aa9b67b9072433ba1007b392d85a2ab":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5793cb1191ad4082bf320e083ec9034a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7946a83fa6eb45e48e6811301dee9564":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4f592a10f67b4b14a97bccc9c70e8b0e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd3e760ee20a45c89b04fbd0808a9908":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cd265e29441d4427b47f66aabcd125a0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e7d3ed1891b343a48a6d188f6f343968","IPY_MODEL_c5d3364115ff4e3ebc894be12d815e68","IPY_MODEL_e686a637024b4f438d9b450674debd34"],"layout":"IPY_MODEL_9217139d18564c7793d32704a1c88743"}},"e7d3ed1891b343a48a6d188f6f343968":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e6e860dd4e4c47928623395bdfa4c750","placeholder":"​","style":"IPY_MODEL_f750fc8478d54bf897fa0b1de4278352","value":"tokenizer.json: 100%"}},"c5d3364115ff4e3ebc894be12d815e68":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6498cf04a06f44a295d1af42cbb65939","max":1961828,"min":0,"orientation":"horizontal","style":"IPY_MODEL_81dd68cca36443259e48840092f5a2dc","value":1961828}},"e686a637024b4f438d9b450674debd34":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4ff03b5cc15c4911845382c2eff8733a","placeholder":"​","style":"IPY_MODEL_0c3c87a1e43249bd9304854e18e6e94c","value":" 1.96M/1.96M [00:00&lt;00:00, 31.4MB/s]"}},"9217139d18564c7793d32704a1c88743":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6e860dd4e4c47928623395bdfa4c750":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f750fc8478d54bf897fa0b1de4278352":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6498cf04a06f44a295d1af42cbb65939":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81dd68cca36443259e48840092f5a2dc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4ff03b5cc15c4911845382c2eff8733a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c3c87a1e43249bd9304854e18e6e94c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d8d199893ea5415aaf79f9347fee979d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ff171dbe58b44c2cb31757c3cfb50d9e","IPY_MODEL_76570276132949beb1b328efeedad276","IPY_MODEL_3ebe6191056e456e9625b53a8c7322c5"],"layout":"IPY_MODEL_b6d43b1b79994dd792358558974f7e62"}},"ff171dbe58b44c2cb31757c3cfb50d9e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fedccc35f181453c8d9336c0116ed533","placeholder":"​","style":"IPY_MODEL_81a877be7f574ad1be794428f7db5b50","value":"config.json: 100%"}},"76570276132949beb1b328efeedad276":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ef8cc5015e034ae5a4edfed2bbb8c625","max":625,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d1eabe24f4f94fc8862db6f9e7497ad4","value":625}},"3ebe6191056e456e9625b53a8c7322c5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b44806dc2a44454091701b9a00189d7a","placeholder":"​","style":"IPY_MODEL_83085ae6fdbe462e809120c8d1ecd6b7","value":" 625/625 [00:00&lt;00:00, 17.1kB/s]"}},"b6d43b1b79994dd792358558974f7e62":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fedccc35f181453c8d9336c0116ed533":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81a877be7f574ad1be794428f7db5b50":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ef8cc5015e034ae5a4edfed2bbb8c625":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d1eabe24f4f94fc8862db6f9e7497ad4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b44806dc2a44454091701b9a00189d7a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83085ae6fdbe462e809120c8d1ecd6b7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"73cc93cf390143ff920f23c1400a7f75":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_895d1d44f22f4c3b8eafcc9bb4a84f99","IPY_MODEL_1159f6df30694b04bc41e39b4fa972a8","IPY_MODEL_ee7292df2e7f4c4e94c42a437d5a6d51"],"layout":"IPY_MODEL_270608a794c9448495ac45d4f53b64cc"}},"895d1d44f22f4c3b8eafcc9bb4a84f99":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_95b9cb7fe908475c919084c931ec4f4a","placeholder":"​","style":"IPY_MODEL_c302aea1a92b4388a1e11e36a7315c50","value":"model.safetensors: 100%"}},"1159f6df30694b04bc41e39b4fa972a8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f4ca022551ba4d23a4e89234f06f56c2","max":714290682,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c7e2732901a542958d663678c24cd06d","value":714290682}},"ee7292df2e7f4c4e94c42a437d5a6d51":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ced3accd30084529aa45dec53f4fefd5","placeholder":"​","style":"IPY_MODEL_fa68385a7b0c4d6590373fbbe0c24e65","value":" 714M/714M [00:07&lt;00:00, 167MB/s]"}},"270608a794c9448495ac45d4f53b64cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95b9cb7fe908475c919084c931ec4f4a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c302aea1a92b4388a1e11e36a7315c50":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f4ca022551ba4d23a4e89234f06f56c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c7e2732901a542958d663678c24cd06d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ced3accd30084529aa45dec53f4fefd5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa68385a7b0c4d6590373fbbe0c24e65":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kvVB6r3hsOTg","executionInfo":{"status":"ok","timestamp":1704711177600,"user_tz":-540,"elapsed":12243,"user":{"displayName":"YuJeong Jeong","userId":"15594695425458788272"}},"outputId":"42b19341-4a58-4118-b358-52cabe72e123"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","source":["import tensorflow as tf\n","import torch\n","\n","from transformers import BertTokenizer\n","from transformers import BertForSequenceClassification, AdamW, BertConfig\n","from transformers import get_linear_schedule_with_warmup\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","\n","import pandas as pd\n","import numpy as np\n","import random\n","import time\n","import datetime"],"metadata":{"id":"utlXsVCtskra","executionInfo":{"status":"ok","timestamp":1704711190713,"user_tz":-540,"elapsed":13117,"user":{"displayName":"YuJeong Jeong","userId":"15594695425458788272"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["data = pd.read_csv('/content/drive/MyDrive/kt AIVLE/BigProject/이진분류데이터.CSV', encoding='cp949')\n","data\n","# 0 : 일상 대화\n","# 1 : 식단 대화"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"_vw6xq-yswmO","executionInfo":{"status":"ok","timestamp":1704711191216,"user_tz":-540,"elapsed":507,"user":{"displayName":"YuJeong Jeong","userId":"15594695425458788272"}},"outputId":"7cecc715-5281-42f0-c9dc-cbc1eb978da9"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["     label                     question\n","0        1    어제 나의 식단 평가가 BAD인 이유가 뭐야?\n","1        1                   나왜 어제 BAD?\n","2        1                     나 왜 BAD?\n","3        1                 내 식단 뭐가 문제야?\n","4        1  어제 나의 식단 평가가 GOOD이던데, 왜그렇지?\n","..     ...                          ...\n","244      1         어제 normal 나온 이유가 뭐지?\n","245      1           어제 good 나온 이유가 뭐지?\n","246      1        어제 perfect 나온 이유가 뭐지?\n","247      0           오늘 먹은 치킨 perfect했다\n","248      0     not bad 한 기분이다 뭐먹으면 좋을까?\n","\n","[249 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-041edb0d-c8d1-4ec7-b65c-f1db93729739\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>question</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>어제 나의 식단 평가가 BAD인 이유가 뭐야?</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>나왜 어제 BAD?</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>나 왜 BAD?</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>내 식단 뭐가 문제야?</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>어제 나의 식단 평가가 GOOD이던데, 왜그렇지?</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>244</th>\n","      <td>1</td>\n","      <td>어제 normal 나온 이유가 뭐지?</td>\n","    </tr>\n","    <tr>\n","      <th>245</th>\n","      <td>1</td>\n","      <td>어제 good 나온 이유가 뭐지?</td>\n","    </tr>\n","    <tr>\n","      <th>246</th>\n","      <td>1</td>\n","      <td>어제 perfect 나온 이유가 뭐지?</td>\n","    </tr>\n","    <tr>\n","      <th>247</th>\n","      <td>0</td>\n","      <td>오늘 먹은 치킨 perfect했다</td>\n","    </tr>\n","    <tr>\n","      <th>248</th>\n","      <td>0</td>\n","      <td>not bad 한 기분이다 뭐먹으면 좋을까?</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>249 rows × 2 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-041edb0d-c8d1-4ec7-b65c-f1db93729739')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-041edb0d-c8d1-4ec7-b65c-f1db93729739 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-041edb0d-c8d1-4ec7-b65c-f1db93729739');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-7d1a8da3-eb59-4d7d-a6a3-8f961524adfc\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7d1a8da3-eb59-4d7d-a6a3-8f961524adfc')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-7d1a8da3-eb59-4d7d-a6a3-8f961524adfc button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_77b82e47-683d-49ed-aaa5-c213a04cca10\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_77b82e47-683d-49ed-aaa5-c213a04cca10 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('data');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["x = data.loc[:, 'question']\n","y = data.loc[:, 'label']\n","x.shape, y.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rj6VWM9Nuk5c","executionInfo":{"status":"ok","timestamp":1704711191216,"user_tz":-540,"elapsed":8,"user":{"displayName":"YuJeong Jeong","userId":"15594695425458788272"}},"outputId":"9f7f708a-4a3a-4b31-ad1a-9505ee228833"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((249,), (249,))"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n","\n","print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0BaUAt6XvNBE","executionInfo":{"status":"ok","timestamp":1704711191217,"user_tz":-540,"elapsed":8,"user":{"displayName":"YuJeong Jeong","userId":"15594695425458788272"}},"outputId":"7d393fdc-55a5-44a8-e937-ef6a2328efef"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["(199,) (50,) (199,) (50,)\n"]}]},{"cell_type":"code","source":["questions = x_train\n","questions[:3]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S6vqcQNgwLuz","executionInfo":{"status":"ok","timestamp":1704711191217,"user_tz":-540,"elapsed":7,"user":{"displayName":"YuJeong Jeong","userId":"15594695425458788272"}},"outputId":"edcee8c5-ff06-4f1e-9964-aa2d2c91b19d"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["132    오늘 저녁엔 축구을 하며 시간을 보낼까 해.\n","156      새로 시작한 날씨 어때? 재미있어 보여!\n","213                식단 평가가 왜 이래?\n","Name: question, dtype: object"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["# BERT 입력 형식에 맞게 변환\n","questions = [\"[CLS] \" + str(question) + \" [SEP]\" for question in questions]\n","questions[:3]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PukHuDeBv-tS","executionInfo":{"status":"ok","timestamp":1704711191217,"user_tz":-540,"elapsed":6,"user":{"displayName":"YuJeong Jeong","userId":"15594695425458788272"}},"outputId":"3fd91a98-2710-49de-9d02-f2c11426fe10"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['[CLS] 오늘 저녁엔 축구을 하며 시간을 보낼까 해. [SEP]',\n"," '[CLS] 새로 시작한 날씨 어때? 재미있어 보여! [SEP]',\n"," '[CLS] 식단 평가가 왜 이래? [SEP]']"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["![대체 텍스트](https://mino-park7.github.io/images/2019/02/bert-input-representation.png)\n","\n","BERT의 입력은 위의 그림과 같은 형식입니다. Classification을 뜻하는 [CLS] 심볼이 제일 앞에 삽입됩니다. 파인튜닝시 출력에서 이 위치의 값을 사용하여 분류를 합니다. [SEP]은 Seperation을 가리키는데, 두 문장을 구분하는 역할을 합니다. 이 예제에서는 문장이 하나이므로 [SEP]도 하나만 넣습니다.\n","<br>\n","<br>\n","<br>"],"metadata":{"id":"9a4J9f0sxHJG"}},{"cell_type":"code","source":["# 라벨 추출\n","labels = y_train.values\n","labels"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cr0IMRUdwKK4","executionInfo":{"status":"ok","timestamp":1704711191668,"user_tz":-540,"elapsed":456,"user":{"displayName":"YuJeong Jeong","userId":"15594695425458788272"}},"outputId":"bf00738d-f5a1-42a3-98b6-7fc8eff9eb2b"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n","       1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n","       0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1,\n","       1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1,\n","       0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n","       1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1,\n","       1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n","       1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n","       1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n","       0])"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["# BERT의 토크나이저로 문장을 토큰으로 분리\n","tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n","tokenized_texts = [tokenizer.tokenize(sent) for sent in questions]\n","\n","print (questions[0])\n","print (tokenized_texts[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":290,"referenced_widgets":["3e4802adb6714afaa1e016970c9d793b","146eb1a2a5eb42bd9d6945d890c36187","2f1b3208c50e46cd9b4944a76283926a","427efcd50fcb4c3ab175849c44e586aa","9c82c611810d4debbf4f5c7da5eb6190","81c0fc7cabc14d74b1ae3170eb5fcf94","e35fc0d848a04f5aa351c1ac0fb4af88","92832dff7945480091f8ac7c8cf5f616","20c19b37eed74650ae6c7078bc64bf7a","04d62922c977427d8fcd28453c5b6eef","60d67f9fa9d7438bb899576d84c575ca","8da36af329a4445b9386a21e3fd0ae3f","a7b7002986be465a80f5a19be3604f45","46148d16b93d4108830d6378be2c53c5","b0baa8fb4b4c4ff2b8356adaf11171a7","baf8ae025ecc4a3eb68cd609858d20d0","13bfcdbd67d04d5a86c89a61039aec5d","0aa9b67b9072433ba1007b392d85a2ab","5793cb1191ad4082bf320e083ec9034a","7946a83fa6eb45e48e6811301dee9564","4f592a10f67b4b14a97bccc9c70e8b0e","fd3e760ee20a45c89b04fbd0808a9908","cd265e29441d4427b47f66aabcd125a0","e7d3ed1891b343a48a6d188f6f343968","c5d3364115ff4e3ebc894be12d815e68","e686a637024b4f438d9b450674debd34","9217139d18564c7793d32704a1c88743","e6e860dd4e4c47928623395bdfa4c750","f750fc8478d54bf897fa0b1de4278352","6498cf04a06f44a295d1af42cbb65939","81dd68cca36443259e48840092f5a2dc","4ff03b5cc15c4911845382c2eff8733a","0c3c87a1e43249bd9304854e18e6e94c","d8d199893ea5415aaf79f9347fee979d","ff171dbe58b44c2cb31757c3cfb50d9e","76570276132949beb1b328efeedad276","3ebe6191056e456e9625b53a8c7322c5","b6d43b1b79994dd792358558974f7e62","fedccc35f181453c8d9336c0116ed533","81a877be7f574ad1be794428f7db5b50","ef8cc5015e034ae5a4edfed2bbb8c625","d1eabe24f4f94fc8862db6f9e7497ad4","b44806dc2a44454091701b9a00189d7a","83085ae6fdbe462e809120c8d1ecd6b7"]},"id":"V3ffY2KQxM5H","executionInfo":{"status":"ok","timestamp":1704711207485,"user_tz":-540,"elapsed":15822,"user":{"displayName":"YuJeong Jeong","userId":"15594695425458788272"}},"outputId":"2099c634-fcae-4f31-d3d7-a0fda644fa4c"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:72: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e4802adb6714afaa1e016970c9d793b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8da36af329a4445b9386a21e3fd0ae3f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd265e29441d4427b47f66aabcd125a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8d199893ea5415aaf79f9347fee979d"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["[CLS] 오늘 저녁엔 축구을 하며 시간을 보낼까 해. [SEP]\n","['[CLS]', '오', '##늘', '저', '##녁', '##엔', '축구', '##을', '하며', '시', '##간을', '보', '##낼', '##까', '해', '.', '[SEP]']\n"]}]},{"cell_type":"markdown","source":["BERT는 형태소분석으로 토큰을 분리하지 않습니다. WordPiece라는 통계적인 방식을 사용합니다. 한 단어내에서 자주 나오는 글자들을 붙여서 하나의 토큰으로 만듭니다. 이렇게 하면 언어에 상관없이 토큰을 생성할 수 있다는 장점이 있습니다. 또한 신조어 같이 사전에 없는 단어를 처리하기도 좋습니다.\n","\n","위의 결과에서 ## 기호는 앞 토큰과 이어진다는 표시입니다. 토크나이저는 여러 언어의 데이터를 기반으로 만든 'bert-base-multilingual-cased'를 사용합니다. 그래서 한글도 처리가 가능합니다.\n","<br>\n","<br>\n","<br>"],"metadata":{"id":"x-yJuBgHxaiT"}},{"cell_type":"code","source":["# 입력 토큰의 최대 시퀀스 길이\n","MAX_LEN = 128\n","\n","# 토큰을 숫자 인덱스로 변환\n","input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","\n","# 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n","input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","input_ids[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UnffxJmaxWHu","executionInfo":{"status":"ok","timestamp":1704711207486,"user_tz":-540,"elapsed":16,"user":{"displayName":"YuJeong Jeong","userId":"15594695425458788272"}},"outputId":"0681ab59-1314-41c5-963e-61bed4fd266c"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([   101,   9580, 118762,   9663, 118738,  86933,  37905,  10622,\n","        64866,   9485,  90295,   9356, 118724, 118671,   9960,    119,\n","          102,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0])"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["보통 딥러닝 모델에는 토큰 자체를 입력으로 넣을 수 없습니다. 임베딩 레이어에는 토큰을 숫자로 된 인덱스로 변환하여 사용합니다. BERT의 토크나이저는 {단어토큰:인덱스}로 구성된 단어사전을 가지고 있습니다. 이를 참조하여 토큰을 인덱스로 바꿔줍니다.\n","<br>\n","<br>\n","<br>"],"metadata":{"id":"i-tftEy0xh1p"}},{"cell_type":"code","source":["# 어텐션 마스크 초기화\n","attention_masks = []\n","\n","# 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n","# 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n","for seq in input_ids:\n","    seq_mask = [float(i>0) for i in seq]\n","    attention_masks.append(seq_mask)\n","\n","print(attention_masks[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VH3g05KrxfZ1","executionInfo":{"status":"ok","timestamp":1704711207486,"user_tz":-540,"elapsed":15,"user":{"displayName":"YuJeong Jeong","userId":"15594695425458788272"}},"outputId":"86c4d45c-3f89-40b1-b8a4-caeb08621838"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"]}]},{"cell_type":"code","source":["# 훈련셋과 검증셋으로 분리\n","train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids,\n","                                                                                    labels,\n","                                                                                    random_state=42,\n","                                                                                    test_size=0.1)\n","\n","# 어텐션 마스크를 훈련셋과 검증셋으로 분리\n","train_masks, validation_masks, _, _ = train_test_split(attention_masks,\n","                                                       input_ids,\n","                                                       random_state=42,\n","                                                       test_size=0.1)\n","\n","# 데이터를 파이토치의 텐서로 변환\n","train_inputs = torch.tensor(train_inputs)\n","train_labels = torch.tensor(train_labels)\n","train_masks = torch.tensor(train_masks)\n","validation_inputs = torch.tensor(validation_inputs)\n","validation_labels = torch.tensor(validation_labels)\n","validation_masks = torch.tensor(validation_masks)\n","\n","print(train_inputs[0])\n","print(train_labels[0])\n","print(train_masks[0])\n","print(validation_inputs[0])\n","print(validation_labels[0])\n","print(validation_masks[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FJ4-VWiVxkYl","executionInfo":{"status":"ok","timestamp":1704711207486,"user_tz":-540,"elapsed":14,"user":{"displayName":"YuJeong Jeong","userId":"15594695425458788272"}},"outputId":"8ece8739-dbbc-4ff4-acd7-0d38377f1c18"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([  101,  9546, 17730, 16626,  8982, 37093,  9638, 42815, 11287,  9303,\n","        12508,   136,   102,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0])\n","tensor(1)\n","tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0.])\n","tensor([   101,   9580, 118762,   9663, 118738,  10892,   9303, 118921,  12508,\n","           136,    102,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0])\n","tensor(0)\n","tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0.])\n"]}]},{"cell_type":"code","source":["# 배치 사이즈\n","batch_size = 32\n","\n","# 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\n","# 학습시 배치 사이즈 만큼 데이터를 가져옴\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n","validation_sampler = SequentialSampler(validation_data)\n","validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"],"metadata":{"id":"qAwqDwDRyzah","executionInfo":{"status":"ok","timestamp":1704711207486,"user_tz":-540,"elapsed":12,"user":{"displayName":"YuJeong Jeong","userId":"15594695425458788272"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# 전처리 - test set\n","questions = x_test\n","questions[:3]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"COMaJ5v6y2zw","executionInfo":{"status":"ok","timestamp":1704711207486,"user_tz":-540,"elapsed":12,"user":{"displayName":"YuJeong Jeong","userId":"15594695425458788272"}},"outputId":"0dddabfb-63b8-442c-ab61-1e4809d0cafc"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["137     어제 not bad가 많은 식사를 했는데 왜 BAD라고 나왔지?\n","6      나 어제 많이 먹었는데도 식단 결과가 perfect야. 왜그러지?\n","97          어제 칼로리가 많은 식사를 했는데 왜 BAD라고 나왔지?\n","Name: question, dtype: object"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["# BERT의 입력 형식에 맞게 변환\n","questions = [\"[CLS] \" + str(question) + \" [SEP]\" for question in questions]\n","questions[:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NyZ8q1OtzC6F","executionInfo":{"status":"ok","timestamp":1704711207486,"user_tz":-540,"elapsed":11,"user":{"displayName":"YuJeong Jeong","userId":"15594695425458788272"}},"outputId":"f10bb2ac-17ad-4d81-8ca0-35eee1220737"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['[CLS] 어제 not bad가 많은 식사를 했는데 왜 BAD라고 나왔지? [SEP]',\n"," '[CLS] 나 어제 많이 먹었는데도 식단 결과가 perfect야. 왜그러지? [SEP]',\n"," '[CLS] 어제 칼로리가 많은 식사를 했는데 왜 BAD라고 나왔지? [SEP]',\n"," '[CLS] 나의 지방 섭취를 줄이려면 어떻게 해야 할까? [SEP]',\n"," '[CLS] 완벽 왜 나옴? [SEP]',\n"," '[CLS] 다음 휴가 때 계획로 여행 가고 싶어. [SEP]',\n"," '[CLS] 어제 내 밥이 어땠지? [SEP]',\n"," '[CLS] 이번 주말은 휴가와 함께 보낼 계획이야. [SEP]',\n"," '[CLS] 식단 평가 결과에 대한 설명을 해줘 [SEP]',\n"," '[CLS] not bad가 왜자꾸 나와? 일주일동안 다 notbad잖아 [SEP]']"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["# 라벨 추출\n","labels = y_test.values\n","labels"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8rw5-m-tzL2b","executionInfo":{"status":"ok","timestamp":1704711207486,"user_tz":-540,"elapsed":9,"user":{"displayName":"YuJeong Jeong","userId":"15594695425458788272"}},"outputId":"962043aa-485e-46de-ab94-94670e1cd5c6"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0,\n","       1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0,\n","       1, 0, 0, 0, 1, 1])"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["# BERT의 토크나이저로 문장을 토큰으로 분리\n","tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n","tokenized_texts = [tokenizer.tokenize(sent) for sent in questions]\n","\n","print (questions[0])\n","print (tokenized_texts[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QCRY13H7zP41","executionInfo":{"status":"ok","timestamp":1704711210895,"user_tz":-540,"elapsed":3415,"user":{"displayName":"YuJeong Jeong","userId":"15594695425458788272"}},"outputId":"b7abb233-c12b-4696-e80a-e7943080bea1"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["[CLS] 어제 not bad가 많은 식사를 했는데 왜 BAD라고 나왔지? [SEP]\n","['[CLS]', '어', '##제', 'not', 'bad', '##가', '많은', '식', '##사를', '했', '##는데', '왜', 'BA', '##D', '##라고', '나', '##왔', '##지', '?', '[SEP]']\n"]}]},{"cell_type":"code","source":["# 입력 토큰의 최대 시퀀스 길이\n","MAX_LEN = 128\n","\n","# 토큰을 숫자 인덱스로 변환\n","input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","\n","# 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n","input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","input_ids[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_B91ZZnfzUGI","executionInfo":{"status":"ok","timestamp":1704711210895,"user_tz":-540,"elapsed":9,"user":{"displayName":"YuJeong Jeong","userId":"15594695425458788272"}},"outputId":"6997b75b-4373-4151-d7ee-b6827af5574c"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([   101,   9546,  17730,  10472,  15838,  11287,  25685,   9486,\n","        32159,   9965,  41850,   9596,  39999,  11490,  59894,   8982,\n","       119163,  12508,    136,    102,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0])"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["# 어텐션 마스크 초기화\n","attention_masks = []\n","\n","# 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n","# 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n","for seq in input_ids:\n","    seq_mask = [float(i>0) for i in seq]\n","    attention_masks.append(seq_mask)\n","\n","print(attention_masks[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3yoH7IS2zVie","executionInfo":{"status":"ok","timestamp":1704711210896,"user_tz":-540,"elapsed":8,"user":{"displayName":"YuJeong Jeong","userId":"15594695425458788272"}},"outputId":"0f95e8c9-7912-4d52-ee7a-629b5feb410f"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"]}]},{"cell_type":"code","source":["# 데이터를 파이토치의 텐서로 변환\n","test_inputs = torch.tensor(input_ids)\n","test_labels = torch.tensor(labels)\n","test_masks = torch.tensor(attention_masks)\n","\n","print(test_inputs[0])\n","print(test_labels[0])\n","print(test_masks[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HU_yVibyzXM4","executionInfo":{"status":"ok","timestamp":1704711210896,"user_tz":-540,"elapsed":6,"user":{"displayName":"YuJeong Jeong","userId":"15594695425458788272"}},"outputId":"3871a706-6b4e-4180-8804-4529a51009fa"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([   101,   9546,  17730,  10472,  15838,  11287,  25685,   9486,  32159,\n","          9965,  41850,   9596,  39999,  11490,  59894,   8982, 119163,  12508,\n","           136,    102,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0])\n","tensor(1)\n","tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0.])\n"]}]},{"cell_type":"code","source":["# 배치 사이즈\n","batch_size = 32\n","\n","# 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\n","# 학습시 배치 사이즈 만큼 데이터를 가져옴\n","test_data = TensorDataset(test_inputs, test_masks, test_labels)\n","test_sampler = RandomSampler(test_data)\n","test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"],"metadata":{"id":"7sslPRGFzYQ5","executionInfo":{"status":"ok","timestamp":1704711210896,"user_tz":-540,"elapsed":4,"user":{"displayName":"YuJeong Jeong","userId":"15594695425458788272"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["## 모델 생성"],"metadata":{"id":"xYXbuPTczamc"}},{"cell_type":"code","source":["# GPU 디바이스 이름 구함\n","device_name = tf.test.gpu_device_name()\n","\n","# GPU 디바이스 이름 검사\n","if device_name == '/device:GPU:0':\n","    print('Found GPU at: {}'.format(device_name))\n","else:\n","    raise SystemError('GPU device not found')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j-CoDZgnzZsp","executionInfo":{"status":"ok","timestamp":1704711211989,"user_tz":-540,"elapsed":1097,"user":{"displayName":"YuJeong Jeong","userId":"15594695425458788272"}},"outputId":"342c431d-b867-425f-87ce-e7bea9299688"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Found GPU at: /device:GPU:0\n"]}]},{"cell_type":"code","source":["# 디바이스 설정\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","else:\n","    device = torch.device(\"cpu\")\n","    print('No GPU available, using the CPU instead.')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eZxXEc36zcY9","executionInfo":{"status":"ok","timestamp":1704711211989,"user_tz":-540,"elapsed":5,"user":{"displayName":"YuJeong Jeong","userId":"15594695425458788272"}},"outputId":"14d65bc0-78ff-4e1c-be9a-b04ade88f4f7"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla T4\n"]}]},{"cell_type":"code","source":["# 분류를 위한 BERT 모델 생성\n","model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=2)\n","model.cuda()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":902,"referenced_widgets":["73cc93cf390143ff920f23c1400a7f75","895d1d44f22f4c3b8eafcc9bb4a84f99","1159f6df30694b04bc41e39b4fa972a8","ee7292df2e7f4c4e94c42a437d5a6d51","270608a794c9448495ac45d4f53b64cc","95b9cb7fe908475c919084c931ec4f4a","c302aea1a92b4388a1e11e36a7315c50","f4ca022551ba4d23a4e89234f06f56c2","c7e2732901a542958d663678c24cd06d","ced3accd30084529aa45dec53f4fefd5","fa68385a7b0c4d6590373fbbe0c24e65"]},"id":"qHbzE9CJztiB","executionInfo":{"status":"ok","timestamp":1704711229661,"user_tz":-540,"elapsed":17675,"user":{"displayName":"YuJeong Jeong","userId":"15594695425458788272"}},"outputId":"7f01d8ed-abcf-4cae-9c5b-615b7175362b"},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73cc93cf390143ff920f23c1400a7f75"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":24}]},{"cell_type":"markdown","source":["![대체 텍스트](http://www.mccormickml.com/assets/BERT/padding_and_mask.png)\n","\n","사전훈련된 BERT는 다양한 문제로 전이학습이 가능합니다. 여기서는 위의 그림과 같이 한 문장을 분류하는 방법을 사용합니다.\n","\n","사용자 질문이 입력으로 들어가면, 0/1(식단평가/일상대화)로 구분한다. 모델의 출력에서 [CLS] 위치인 첫 번째 토큰에 새로운 레이어를 붙여서 파인튜닝을 합니다. Huggning Face는 BertForSequenceClassification() 함수를 제공하기 때문에 쉽게 구현할 수 있습니다.\n","<br>\n","<br>\n","<br>"],"metadata":{"id":"8r3oIuNWz2Vi"}},{"cell_type":"code","source":["# 옵티마이저 설정\n","optimizer = AdamW(model.parameters(),\n","                  lr = 2e-5, # 학습률\n","                  eps = 1e-8 # 0으로 나누는 것을 방지하기 위한 epsilon 값\n","                )\n","\n","# 에폭수\n","epochs = 10\n","\n","# 총 훈련 스텝 : 배치반복 횟수 * 에폭\n","total_steps = len(train_dataloader) * epochs\n","\n","# 처음에 학습률을 조금씩 변화시키는 스케줄러 생성\n","scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                            num_warmup_steps = 0,\n","                                            num_training_steps = total_steps)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LeyTLCtOzyQq","executionInfo":{"status":"ok","timestamp":1704711230026,"user_tz":-540,"elapsed":367,"user":{"displayName":"YuJeong Jeong","userId":"15594695425458788272"}},"outputId":"19f4bb35-2294-4ccd-d7eb-0dcb881c8791"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}]},{"cell_type":"markdown","source":["## 모델 학습"],"metadata":{"id":"PcQuHElQ0Ifr"}},{"cell_type":"code","source":["# 정확도 계산 함수\n","def flat_accuracy(preds, labels):\n","\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"metadata":{"id":"z2CCYf-s0Gnk","executionInfo":{"status":"ok","timestamp":1704711230533,"user_tz":-540,"elapsed":5,"user":{"displayName":"YuJeong Jeong","userId":"15594695425458788272"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["# 시간 표시 함수\n","def format_time(elapsed):\n","\n","    # 반올림\n","    elapsed_rounded = int(round((elapsed)))\n","\n","    # hh:mm:ss으로 형태 변경\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"metadata":{"id":"aaVaETpq0KgK","executionInfo":{"status":"ok","timestamp":1704711230534,"user_tz":-540,"elapsed":4,"user":{"displayName":"YuJeong Jeong","userId":"15594695425458788272"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["# 재현을 위해 랜덤시드 고정\n","seed_val = 42\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","# 그래디언트 초기화\n","model.zero_grad()\n","\n","# 에폭만큼 반복\n","for epoch_i in range(0, epochs):\n","\n","    # ========================================\n","    #               Training\n","    # ========================================\n","\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # 시작 시간 설정\n","    t0 = time.time()\n","\n","    # 로스 초기화\n","    total_loss = 0\n","\n","    # 훈련모드로 변경\n","    model.train()\n","\n","    # 데이터로더에서 배치만큼 반복하여 가져옴\n","    for step, batch in enumerate(train_dataloader):\n","        # 경과 정보 표시\n","        if step % 500 == 0 and not step == 0:\n","            elapsed = format_time(time.time() - t0)\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        # 배치를 GPU에 넣음\n","        batch = tuple(t.to(device) for t in batch)\n","\n","        # 배치에서 데이터 추출\n","        b_input_ids, b_input_mask, b_labels = batch\n","\n","        # Forward 수행\n","        outputs = model(b_input_ids,\n","                        token_type_ids=None,\n","                        attention_mask=b_input_mask,\n","                        labels=b_labels)\n","\n","        # 로스 구함\n","        loss = outputs[0]\n","\n","        # 총 로스 계산\n","        total_loss += loss.item()\n","\n","        # Backward 수행으로 그래디언트 계산\n","        loss.backward()\n","\n","        # 그래디언트 클리핑\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # 그래디언트를 통해 가중치 파라미터 업데이트\n","        optimizer.step()\n","\n","        # 스케줄러로 학습률 감소\n","        scheduler.step()\n","\n","        # 그래디언트 초기화\n","        model.zero_grad()\n","\n","    # 평균 로스 계산\n","    avg_train_loss = total_loss / len(train_dataloader)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n","\n","    # ========================================\n","    #               Validation\n","    # ========================================\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    #시작 시간 설정\n","    t0 = time.time()\n","\n","    # 평가모드로 변경\n","    model.eval()\n","\n","    # 변수 초기화\n","    eval_loss, eval_accuracy = 0, 0\n","    nb_eval_steps, nb_eval_examples = 0, 0\n","\n","    # 데이터로더에서 배치만큼 반복하여 가져옴\n","    for batch in validation_dataloader:\n","        # 배치를 GPU에 넣음\n","        batch = tuple(t.to(device) for t in batch)\n","\n","        # 배치에서 데이터 추출\n","        b_input_ids, b_input_mask, b_labels = batch\n","\n","        # 그래디언트 계산 안함\n","        with torch.no_grad():\n","            # Forward 수행\n","            outputs = model(b_input_ids,\n","                            token_type_ids=None,\n","                            attention_mask=b_input_mask)\n","\n","        # 출력 로짓 구함\n","        logits = outputs[0]\n","\n","        # CPU로 데이터 이동\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        # 출력 로짓과 라벨을 비교하여 정확도 계산\n","        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","        eval_accuracy += tmp_eval_accuracy\n","        nb_eval_steps += 1\n","\n","    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n","    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n","\n","print(\"\")\n","print(\"Training complete!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A1K4cBJx0LdI","executionInfo":{"status":"ok","timestamp":1704711264864,"user_tz":-540,"elapsed":34334,"user":{"displayName":"YuJeong Jeong","userId":"15594695425458788272"}},"outputId":"2a66e2c6-8a66-4f36-b216-c9c01191ab3c"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======== Epoch 1 / 10 ========\n","Training...\n","\n","  Average training loss: 0.63\n","  Training epcoh took: 0:00:04\n","\n","Running Validation...\n","  Accuracy: 0.75\n","  Validation took: 0:00:00\n","\n","======== Epoch 2 / 10 ========\n","Training...\n","\n","  Average training loss: 0.44\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.75\n","  Validation took: 0:00:00\n","\n","======== Epoch 3 / 10 ========\n","Training...\n","\n","  Average training loss: 0.32\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.85\n","  Validation took: 0:00:00\n","\n","======== Epoch 4 / 10 ========\n","Training...\n","\n","  Average training loss: 0.25\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.85\n","  Validation took: 0:00:00\n","\n","======== Epoch 5 / 10 ========\n","Training...\n","\n","  Average training loss: 0.19\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.85\n","  Validation took: 0:00:00\n","\n","======== Epoch 6 / 10 ========\n","Training...\n","\n","  Average training loss: 0.15\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.85\n","  Validation took: 0:00:00\n","\n","======== Epoch 7 / 10 ========\n","Training...\n","\n","  Average training loss: 0.10\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.90\n","  Validation took: 0:00:00\n","\n","======== Epoch 8 / 10 ========\n","Training...\n","\n","  Average training loss: 0.07\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.95\n","  Validation took: 0:00:00\n","\n","======== Epoch 9 / 10 ========\n","Training...\n","\n","  Average training loss: 0.04\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.95\n","  Validation took: 0:00:00\n","\n","======== Epoch 10 / 10 ========\n","Training...\n","\n","  Average training loss: 0.04\n","  Training epcoh took: 0:00:03\n","\n","Running Validation...\n","  Accuracy: 0.95\n","  Validation took: 0:00:00\n","\n","Training complete!\n"]}]},{"cell_type":"markdown","source":["## 테스트셋 평가"],"metadata":{"id":"b2gqSHrn0VZk"}},{"cell_type":"code","source":["#시작 시간 설정\n","t0 = time.time()\n","\n","# 평가모드로 변경\n","model.eval()\n","\n","# 변수 초기화\n","eval_loss, eval_accuracy = 0, 0\n","nb_eval_steps, nb_eval_examples = 0, 0\n","\n","# 데이터로더에서 배치만큼 반복하여 가져옴\n","for step, batch in enumerate(test_dataloader):\n","    # 경과 정보 표시\n","    if step % 100 == 0 and not step == 0:\n","        elapsed = format_time(time.time() - t0)\n","        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n","\n","    # 배치를 GPU에 넣음\n","    batch = tuple(t.to(device) for t in batch)\n","\n","    # 배치에서 데이터 추출\n","    b_input_ids, b_input_mask, b_labels = batch\n","\n","    # 그래디언트 계산 안함\n","    with torch.no_grad():\n","        # Forward 수행\n","        outputs = model(b_input_ids,\n","                        token_type_ids=None,\n","                        attention_mask=b_input_mask)\n","\n","    # 출력 로짓 구함\n","    logits = outputs[0]\n","\n","    # CPU로 데이터 이동\n","    logits = logits.detach().cpu().numpy()\n","    label_ids = b_labels.to('cpu').numpy()\n","\n","    # 출력 로짓과 라벨을 비교하여 정확도 계산\n","    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","    eval_accuracy += tmp_eval_accuracy\n","    nb_eval_steps += 1\n","\n","print(\"\")\n","print(\"Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n","print(\"Test took: {:}\".format(format_time(time.time() - t0)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9mnDTGs60QkH","executionInfo":{"status":"ok","timestamp":1704711265533,"user_tz":-540,"elapsed":672,"user":{"displayName":"YuJeong Jeong","userId":"15594695425458788272"}},"outputId":"c75c4638-ec0d-4e31-b0a0-d0c7d69698ca"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Accuracy: 0.95\n","Test took: 0:00:00\n"]}]},{"cell_type":"markdown","source":["## 새로운 문장 테스트"],"metadata":{"id":"BiU5_R-D0Yqu"}},{"cell_type":"code","source":["# 입력 데이터 변환\n","def convert_input_data(sentences):\n","\n","    # BERT의 토크나이저로 문장을 토큰으로 분리\n","    tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n","\n","    # 입력 토큰의 최대 시퀀스 길이\n","    MAX_LEN = 128\n","\n","    # 토큰을 숫자 인덱스로 변환\n","    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","\n","    # 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n","    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","    # 어텐션 마스크 초기화\n","    attention_masks = []\n","\n","    # 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n","    # 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n","    for seq in input_ids:\n","        seq_mask = [float(i>0) for i in seq]\n","        attention_masks.append(seq_mask)\n","\n","    # 데이터를 파이토치의 텐서로 변환\n","    inputs = torch.tensor(input_ids)\n","    masks = torch.tensor(attention_masks)\n","\n","    return inputs, masks"],"metadata":{"id":"vlv_9DVN0XeZ","executionInfo":{"status":"ok","timestamp":1704711265534,"user_tz":-540,"elapsed":11,"user":{"displayName":"YuJeong Jeong","userId":"15594695425458788272"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["# 문장 테스트\n","def test_sentences(sentences):\n","\n","    # 평가모드로 변경\n","    model.eval()\n","\n","    # 문장을 입력 데이터로 변환\n","    inputs, masks = convert_input_data(sentences)\n","\n","    # 데이터를 GPU에 넣음\n","    b_input_ids = inputs.to(device)\n","    b_input_mask = masks.to(device)\n","\n","    # 그래디언트 계산 안함\n","    with torch.no_grad():\n","        # Forward 수행\n","        outputs = model(b_input_ids,\n","                        token_type_ids=None,\n","                        attention_mask=b_input_mask)\n","\n","    # 출력 로짓 구함\n","    logits = outputs[0]\n","\n","    # CPU로 데이터 이동\n","    logits = logits.detach().cpu().numpy()\n","\n","    return logits"],"metadata":{"id":"x75mwhTv0blV","executionInfo":{"status":"ok","timestamp":1704711265534,"user_tz":-540,"elapsed":10,"user":{"displayName":"YuJeong Jeong","userId":"15594695425458788272"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["logits = test_sentences(['연기는 별로지만 재미 하나는 끝내줌!'])\n","\n","print(logits)\n","print(np.argmax(logits))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BWGdHqzF0cqL","executionInfo":{"status":"ok","timestamp":1704711265534,"user_tz":-540,"elapsed":9,"user":{"displayName":"YuJeong Jeong","userId":"15594695425458788272"}},"outputId":"37fa1efc-5227-480b-f00c-af4a37866635"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 0.6993255 -0.6175229]]\n","0\n"]}]},{"cell_type":"code","source":["def classification(question):\n","  logits = test_sentences([question])\n","\n","  #print(logits)\n","  print(np.argmax(logits))"],"metadata":{"id":"iTWRa3uQXYKx","executionInfo":{"status":"ok","timestamp":1704711603981,"user_tz":-540,"elapsed":313,"user":{"displayName":"YuJeong Jeong","userId":"15594695425458788272"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["classification('주연배우가 아깝다. 총체적 난국...')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AvwH8ka8XhtX","executionInfo":{"status":"ok","timestamp":1704711265534,"user_tz":-540,"elapsed":7,"user":{"displayName":"YuJeong Jeong","userId":"15594695425458788272"}},"outputId":"922dfd6e-b129-4112-e7a6-749630d846cd"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 0.63165456 -0.9142001 ]]\n","0\n"]}]},{"cell_type":"code","source":["classification('12월 3일에 내 식단 결과가 왜저래?')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IhVeldxY0hEk","executionInfo":{"status":"ok","timestamp":1704711265534,"user_tz":-540,"elapsed":6,"user":{"displayName":"YuJeong Jeong","userId":"15594695425458788272"}},"outputId":"44e2d300-ae67-450e-db9e-87321314f41b"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["[[-2.2620192  2.2421746]]\n","1\n"]}]},{"cell_type":"code","source":["classification('오늘 점심 뭐먹을까?')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B8XVpGT10tB2","executionInfo":{"status":"ok","timestamp":1704711266073,"user_tz":-540,"elapsed":543,"user":{"displayName":"YuJeong Jeong","userId":"15594695425458788272"}},"outputId":"92a35ab3-b091-42b9-ff20-9e31edc763f0"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 1.8437881 -1.6767255]]\n","0\n"]}]},{"cell_type":"code","source":["classification('내가 건강하려면 뭐 먹어야돼?')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z3_9qZtU0vuu","executionInfo":{"status":"ok","timestamp":1704711266073,"user_tz":-540,"elapsed":13,"user":{"displayName":"YuJeong Jeong","userId":"15594695425458788272"}},"outputId":"6a3ce5cb-a102-48ed-f00e-adb3f8386231"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 1.3531675 -1.2658767]]\n","0\n"]}]},{"cell_type":"code","source":["classification('안녕')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2IBxpP6F00Cl","executionInfo":{"status":"ok","timestamp":1704711266074,"user_tz":-540,"elapsed":12,"user":{"displayName":"YuJeong Jeong","userId":"15594695425458788272"}},"outputId":"f1463a18-42b2-4fa0-f470-33dab0b397ec"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.07436302 0.15608685]]\n","1\n"]}]},{"cell_type":"code","source":["classification('나 왜 오늘 bad 야?')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pqp5Esub02ra","executionInfo":{"status":"ok","timestamp":1704711266074,"user_tz":-540,"elapsed":10,"user":{"displayName":"YuJeong Jeong","userId":"15594695425458788272"}},"outputId":"9f670b90-3a73-43c7-d251-edf179e1411b"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["[[-2.1737378  2.1705117]]\n","1\n"]}]},{"cell_type":"code","source":["classification('나왜오늘bad야?')"],"metadata":{"id":"ULHePVK5YKGX","executionInfo":{"status":"ok","timestamp":1704711608528,"user_tz":-540,"elapsed":328,"user":{"displayName":"YuJeong Jeong","userId":"15594695425458788272"}},"outputId":"a080ea77-1ebf-4624-ad0b-3b6b99d46d7f","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n"]}]},{"cell_type":"code","source":["logits = test_sentences(['오늘 치킨 perfect'])\n","\n","print(logits)\n","print(np.argmax(logits))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jFN0b-PXSIoh","executionInfo":{"status":"ok","timestamp":1704711266074,"user_tz":-540,"elapsed":7,"user":{"displayName":"YuJeong Jeong","userId":"15594695425458788272"}},"outputId":"afb5a93c-d836-471f-ae73-4b2877568766"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 1.5711664 -1.6202947]]\n","0\n"]}]},{"cell_type":"code","source":["logits = test_sentences(['왜 bad'])\n","\n","print(logits)\n","print(np.argmax(logits))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8_NnmdcLSK-z","executionInfo":{"status":"ok","timestamp":1704711266074,"user_tz":-540,"elapsed":6,"user":{"displayName":"YuJeong Jeong","userId":"15594695425458788272"}},"outputId":"e4aa1de2-97b1-4683-c184-e7b805f08fac"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.07020324 0.16676041]]\n","1\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"qdLNsiYsSQny","executionInfo":{"status":"ok","timestamp":1704711266074,"user_tz":-540,"elapsed":5,"user":{"displayName":"YuJeong Jeong","userId":"15594695425458788272"}}},"execution_count":42,"outputs":[]}]}